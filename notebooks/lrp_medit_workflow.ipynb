{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LRP Medit (Resnet) Notebook\n",
    "In this notebook we deploy our LRPEngine on the **Resnet-based wound classification model**. As comprehensibly described in one provided paper (see \"literature/lrp_resnet\"), the implementation of LRP on models with residual connections (as ResNet) is non-trivial."
   ],
   "id": "6637844b33fa5fac"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import v2\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.xai.lrp import LRPEngine\n",
    "import medit_classifier.medit_resnet_model as medit_classifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# constant variables in capital letters:\n",
    "MEDIT_PATH = \"../medit_classifier/\"\n",
    "OUTPUT_PATH = \"../output/241128 lrp_heatmaps/\"\n",
    "STAGE1_OUTPUT = OUTPUT_PATH + \"stage1/\"\n",
    "STAGE2_OUTPUT = OUTPUT_PATH + \"stage2/\"\n",
    "STAGE3_OUTPUT = OUTPUT_PATH + \"stage3/\"\n",
    "STAGE4_OUTPUT = OUTPUT_PATH + \"stage4/\"\n",
    "\n",
    "MODEL_PATH = MEDIT_PATH + 'Resnet50_v2_learning rate_0.001_loss_function_CrossEntropyLoss_batch_size_16_dropout_False_20241027_023602_savedepoch_2.pth'\n",
    "CONFIG_PATH = MEDIT_PATH + 'Resnet50_v2_learning rate_0.001_loss_function_CrossEntropyLoss_batch_size_16_dropout_False_20241027_023602.json'\n",
    "PRED_PATH = MEDIT_PATH + 'saved/'\n",
    "\n",
    "DATASET = MEDIT_PATH + 'Dataset_reduced/'\n",
    "STAGE1_DATA = DATASET + '1/'\n",
    "STAGE2_DATA = DATASET + '2/'\n",
    "STAGE3_DATA = DATASET + '3/'\n",
    "STAGE4_DATA = DATASET + '4/'"
   ],
   "id": "534264957b7b44ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Model Initialisation",
   "id": "3d5414d0df4daa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = medit_classifier.initialise_model(CONFIG_PATH, MODEL_PATH)",
   "id": "aa5e5d9c10ba9b90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. LRP Workflow",
   "id": "2b939b3af4807655"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def lrp_workflow(classifier_model, image_directory, output_directory=None, rel_filter_ratio=0.75, layers_to_inspect=[0, 10, 20], check_already_calculated=True):\n",
    "    # initialise LRP engine:\n",
    "    lrp_engine = LRPEngine(classifier_model, plot_output_dir=output_directory)\n",
    "    \n",
    "    # already calculated check can be overwritten by start_after and requires an output dict:\n",
    "    if check_already_calculated and output_directory is not None:\n",
    "        # use set to prevent duplicates:\n",
    "        files_calculated = {title.split('Calc ')[1].split(' class')[0] for title in os.listdir(output_directory)}\n",
    "\n",
    "    # iterate over files (tqdm yields a progress bar but requires the len of iterable (total) if it's a generator)\n",
    "    for i, file in tqdm(enumerate(os.listdir(image_directory)), total=len(os.listdir(image_directory)), ncols=80, position=0, leave=True):\n",
    "        file_title = file.split('.')[0]\n",
    "        if check_already_calculated and output_directory is not None:\n",
    "            if file_title in files_calculated:\n",
    "                print(f\"{file_title} already calculated. Skipping!\")\n",
    "                continue\n",
    "            \n",
    "        # load image:\n",
    "        image_path = os.path.join(image_directory, file)\n",
    "        try:\n",
    "            _, img_tensor = medit_classifier.load_img_and_tensor(image_path)\n",
    "        except BaseException as err:\n",
    "            print(err)\n",
    "            continue\n",
    "\n",
    "        # calculate LRP:\n",
    "        lrp_engine.input_batch = img_tensor.unsqueeze(0)\n",
    "        lrp_engine.calculate_relevance_scores(rel_filter_ratio=rel_filter_ratio)\n",
    "\n",
    "        # plot and save output results:\n",
    "        for layer_ind in layers_to_inspect:\n",
    "            lrp_engine.plot_relevance_scores(layer_ind, input_reference=file_title, hidden=True, plt_cmap='bwr')"
   ],
   "id": "5e002e756b2c46e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1. Stage 1 Picture Analysis",
   "id": "eed13ad1f8df0144"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lrp_workflow(model, STAGE1_DATA, STAGE1_OUTPUT)",
   "id": "7ec68b0fba5a3579",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2. Stage 2 Picture Analysis",
   "id": "d257af2c01a0169b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lrp_workflow(model, STAGE2_DATA, STAGE2_OUTPUT)",
   "id": "35a347da67c25433",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3. Stage 3 Picture Analysis",
   "id": "7174140c7b294c10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lrp_workflow(model, STAGE3_DATA, STAGE3_OUTPUT)",
   "id": "e71bced6e05ed9c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3. Stage 4 Picture Analysis",
   "id": "bd8f232fe59549e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lrp_workflow(model, STAGE4_DATA, STAGE4_OUTPUT)",
   "id": "889bd68b3eeedbe0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "af7ba1b5dde160ca",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
